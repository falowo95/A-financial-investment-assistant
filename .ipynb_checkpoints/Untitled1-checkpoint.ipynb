{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab678aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation of needed packages \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "import plotly.graph_objs as go\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56248808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(i):\n",
    "    model =load_model(f\"{i}_predictive_model.h5\")\n",
    "    start_date = dt.datetime(2012, 1, 1)\n",
    "    end_date = dt.datetime(2020, 1, 1)\n",
    "    data = web.DataReader(i, 'yahoo', start_date, end_date)\n",
    "\n",
    "    #now we will see how well the model will perfom on past data data we already have \n",
    "    #testing the model accuracy on existing data data the model has not seen before \n",
    "    \n",
    "\n",
    "\n",
    "    test_start_date=dt.datetime(2020, 1, 1)\n",
    "    test_end_date=dt.datetime.now()\n",
    "    test_data = web.DataReader(i, 'yahoo', test_start_date, test_end_date)\n",
    "\n",
    "\n",
    "    prediction_days = 60\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "    scaled_DATA = scaler.fit_transform(data.Close.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "    actual_prices = test_data['Close'].values\n",
    "\n",
    "    #data containing both the training data and the test data\n",
    "    total_dataset = pd.concat((data.Close, test_data.Close),axis= 0)\n",
    "\n",
    "\n",
    "    #this is what the model will take in as input \n",
    "    model_inputs = total_dataset[len(total_dataset) - len(test_data)- prediction_days:].values\n",
    "\n",
    "    #we now have to reshape the model inputs from the new dataframe\n",
    "    model_inputs = model_inputs.reshape(-1,1)\n",
    "\n",
    "    #now we have to scale it down with the existing scaler\n",
    "    model_inputs = scaler.transform(model_inputs)\n",
    "\n",
    "\n",
    "    #now we will predict based on the data we have not seen before (test data)\n",
    "    #here we evaluate how well our model performs on test data \n",
    "    x_test = []\n",
    "    for x in range (prediction_days,len(model_inputs) + 1):\n",
    "        x_test.append(model_inputs[x-prediction_days:x, 0])\n",
    "    #we dont need ytest here because we already have the actual stock prices \n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = np.reshape(x_test,(x_test.shape[0], x_test.shape[1],1))\n",
    "\n",
    "\n",
    "    predicted_prices = model.predict(x_test)\n",
    "\n",
    "    #because the prices were scaled before we now rescale them back to the actual prices\n",
    "    predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "\n",
    "\n",
    "    #predict next day \n",
    "    real_data = [model_inputs[len(model_inputs) - prediction_days:len(model_inputs + 1), 0]]\n",
    "    real_data = np.array(real_data)\n",
    "    real_data = np.reshape(real_data,(real_data.shape[0], real_data.shape[1],1))\n",
    "\n",
    "\n",
    "    prediction = model.predict(real_data)\n",
    "    prediction = scaler.inverse_transform(prediction)\n",
    "    response = f\"{i.upper()} Price Prediction for tomorrow is  : {prediction}\"\n",
    "    print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a53434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 02:53:21.022608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-19 02:53:21.280327: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-19 02:53:21.772055: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-19 02:53:21.927102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BABA Price Prediction for tomorrow is  : [[84.57179]]\n"
     ]
    }
   ],
   "source": [
    "prediction(\"baba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35abc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = \"fb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9535c4e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./trained_models/fb_predictive_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./trained_models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_predictive_model.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/saving/save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at ./trained_models/fb_predictive_model.h5"
     ]
    }
   ],
   "source": [
    "  model =load_model(f\"./trained_models/{i}_predictive_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d3304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/falowogbolahan/Documents/MASTERS PROJECT/code/trunk/pythonProject1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2dce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
